\documentclass{article}
\usepackage[sorting=none]{biblatex}
\addbibresource{references.bib}

\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,verbatim}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmicx}

\usepackage{graphicx}
\usepackage{algpseudocode}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[bb=boondox]{mathalfa}
\usepackage{enumerate}
\usepackage{xcolor}

\renewcommand{\algorithmiccomment}[1]{{\footnotesize\hfill$\triangleright$ #1}}

\renewcommand{\P}{\mathbf{P}}
\newcommand{\NP}{\mathbf{NP}}
\newcommand{\coNP}{\mathbf{coNP}}
\newcommand{\EXP}{\mathbf{EXP}}
\newcommand{\BPP}{\mathbf{BPP}}
\newcommand{\RP}{\mathbf{RP}}
\newcommand{\NEXP}{\mathbf{NEXP}}
\newcommand{\PH}{\mathbf{PH}}
\newcommand{\PSPACE}{\mathbf{PSPACE}}
\newcommand{\TIME}{\mathbf{TIME}}
\newcommand{\NTIME}{\mathbf{NTIME}}
\newcommand{\LOG}{\mathbf{LOGSPACE}}
\newcommand{\SIZE}{\mathbf{SIZE}}

\def \F {{\mathbb F}}
\def \N {{\mathbb N}}

\def \ATIME{{\mathsf{ATIME}}}
\def \NTIME{{\mathsf{NTIME}}}
\def \eps {{\varepsilon}}

\def \ASPACE{{\mathsf{ASPACE}}}
\def \SPACE{{\mathsf{SPACE}}}
\def \TIME{{\mathsf{TIME}}}
\def \BPL{{\mathbf{BPL}}}

\def \poly{\text{poly}}

\def \Ygood{\mathcal{Y}_\text{good}}
\def \Rgood{\mathcal{R}_\text{good}}
\def \by{{\bar{y}}}

\theoremstyle{definition}

\newtheorem{defn}{Definition}
\newtheorem*{defn*}{Definition}
\newtheorem*{notn*}{Notation}

\newtheorem{thm}{Theorem}
\newtheorem*{thm*}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{prop*}{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem*{cor*}{Corollary}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\newtheorem*{recall}{Recall}

\def \Pa{\text{Pa}}

\begin{document}

\begin{center}
    \Large
    Are there Bayesian networks in which posterior inference is often difficult?

    \vspace{3pt}
    \normalsize
    George Matheos, \today
\end{center}

\section{Posterior inference and computation}

\subsection{Posterior inference}

A central computational problem in science and artificial intelligence is posterior inference in probabilistic models.
Consider a probability distribution $P$ on a space $X \times Y \times Z$.
For the purposes of this paper, we will take $X, Y, Z \subseteq \{0, 1\}^*$.
The problem of posterior inference is to characterize the posterior distribution
$$
P(X = \cdot | Y = y)
$$
for a value $y \in Y$ s.t. $P(Y = y) > 0$.

To define this formally, we must first define the marginal distributions
$$
P(X = x, Y = y) := \sum_{z \in Z} P(x, y, z); \quad P(Y = y) := \sum_{(x, z) \in X \times Z} P(x, y, z)
$$
With these definitions in hand, the posterior $P(X = \cdot | Y = y)$ is the probability distribution such that for all $x \in X$,
$$
P(X = x | Y = y) := \frac{P(X = x, Y = y)}{P(Y = y)}
$$

Stated informally, the problem of posterior inference is:
\textit{given a probabilistic model $P$ and a value $y$ with $P(Y = y) > 0$, characerize $P(X = x | Y = y)$}.

\subsection{Computational formulations of exact inference}
% The posterior $P(X = \cdot | Y = y)$ is a probability distribution on the space $X$.
% While it is desirable to have algorithms which can characterize these posteriors, there is no one canonical representation of a probability distribution for an algorithm to output.
% Hence, there are several distinct formulations of what it means for an algorithm
To formalize the problem of posterior inference as a specification a computer algorithm could satisfy, we must specify what it would mean for an algorithm to ``characterize'' a probability distribution on the space $X$, as this is the type of mathematical object that $P(X = x | Y = y)$ is.
There are several distinct algorithmic formulations:
\begin{enumerate}
    \item \textbf{Probability mass function (PMF) computation.} Given a value $x \in X, y \in Y$, compute the number $P(X = x | Y = y)$.
    \item \textbf{Cumulative distribution function (CDF) computation.} Given a value $x \in X, y \in Y$, and letting strings in $x \in X \subseteq \{0, 1\}^*$ have lexographic ordering, compute the number $P(X \leq x | Y = y)$.
    \item \textbf{Sampling.} Given a value $y \in Y$, sample a random value in $X$ according to the distribution $P(X = x | Y = y)$.  This requires the use of a probabilistic Turing machine.  Under standard formulations, this means we want a Turing machine $A$ which, given $y \in Y$ and an uniformly random bit sequence $r \in \{0, 1\}^*$, computes a value $A(y, r) \in X$ such that for all $x \in X$, $P(X = x | Y = y) = \Pr_r[x = A(y, r)]$.
    % \item \textbf{Expected value computation.} Given a value $y \in Y$ and a function $f : X \to \mathbb{R}$, compute the expected value $\mathbb{E}_{x \sim P(X = \cdot | Y = y)}[f(x)]$.  To make this formulation precise, we need a manner in which the function $f$ is represented using a bit string which can be input to an algorithm, and we need to specify how the outputs of $f$ are represented as bit strings.  Due to this complexity, the complexity theory literature appears to 
\end{enumerate}

% There are a number of reductions among these:
% \begin{enumerate}
%     \item If algorithm $A$ performs CDF computation, then it is possible to perform PMF computation by computing $P(X = x | Y = y) = \textsf{CDF}(x, y) - \textsf{CDF}(x - 1, y)$.
%     \item If algorithm $A$ performs sampling, 
% \end{enumerate}

\subsection{Computational formulations of approximate inference}
It usually suffices for algorithms to perform approximate probabilistic inference.
There are several standard formulations of approximate probabilistic inference as computational problems:
\begin{enumerate}
    \item \textbf{PMF evalution up to additive error.} Fix $\epsilon > 0$.  Algorithm $A$ does PMF evaluation in $P$ up to additive error $\epsilon$ if for any $x \in X, y \in Y$, it computes a number $A(x, y)$ where $|A(x, y) - P(X = x | Y = y)| < \epsilon$.
    \item \textbf{PMF evaluation up to relative error.} Fix $\epsilon > 0$.  Algorithm $A$ does PMF evaluation in $P$ up to relative error $\epsilon$ if for any $x \in X, y \in Y$, it computes a number $A(x, y) \in (\frac{1}{1 + \epsilon}P(X = x | Y = y), (1 + \epsilon)P(X = x | Y = y))$
    \item \textbf{CDF evaluation up to additive error.} Fix $\epsilon > 0$.  Algorithm $A$ does CDF evaluation in $P$ up to additive error $\epsilon$ if for any $x \in X, y \in Y$, it computes a number $A(x, y)$ where $|A(x, y) - P(X \leq x | Y = y)| < \epsilon$.
    \item \textbf{CDF evaluation up to relative error.} Fix $\epsilon > 0$.  Algorithm $A$ does CDF evaluation in $P$ up to relative error $\epsilon$ if for any $x \in X, y \in Y$, it computes a number $A(x, y) \in (\frac{1}{1 + \epsilon}P(X \leq x | Y = y), (1 + \epsilon)P(X \leq x | Y = y))$.
    \item \textbf{Approximate sampling with pointwise probability bounds.} There are several formulations of approximate sampling. One formulation is to say that probabilistic algorithm $A(y, r)$ (for random bitstring $r$) approximately samples from $P(X = x | Y = y)$ up to pointwise error $\delta$ if for all $x \in X$, $|\Pr_r[A(y, r) = x] - P(X = x | Y = y)| < \delta$.
\end{enumerate}
For any of the PMF or CDF computation problems, a probabilistic version can be defined in which a probabilistic algorithm $A$ is said to do PMF or CDF computation iff it satisfies the above specification with probability $\geq 2/3$ on any input.

\subsection{Some hardness relationships among these formulations}

A number of relationships are known between the hardness of inference according to these different formulations.
Below, I will articulate a subset of these which indicate that if it is computationally hard to do 
probabilistic PMF computation up to additive error, then it is computationally difficult to solve any of the aformentinoed inference problems.

\begin{enumerate}
    \item \textbf{Relative approximation for is harder than additive approximation for equal $\epsilon$.}
    Consider a true PMF or CDF value $p$. If $\epsilon \geq 1$ then additive PMF or CDF approximation is trivial, so consider an $\epsilon < 1$.
    Since $p \in [0, 1]$, if $\hat{p}$ satisfies $\hat{p} \in (p/(1+\epsilon), (1+\epsilon)p)$, then $$|\hat{p} - p| \leq \max(|(1 + \epsilon)p - p|, |p/(1+\epsilon) - p|) \leq \max(|1 + \epsilon - 1|, |1/(1+\epsilon) - 1|) = \epsilon$$
    Thus if it is possible to compute a relative $\epsilon$ approximation to either CDF or PMF, it is also possible to compute an additive $\epsilon$ approximation to the same quantity.

    \item \textbf{CDF computation is harder than PMF computation.} 
        \begin{enumerate}
            \item \textit{Exact computation.} Say $\mathsf{CDF}(x, y) := P(X \leq x | Y = y)$ can be computed exactly.  Then we can compute $\mathsf{PMF}(x, y) := P(X = x | Y = y) = \mathsf{CDF}(x, y) - \mathsf{CDF}(x - 1, y)$.
            \item \textit{Additive approximation.} Say we can compute an additive $\epsilon$ approximation $\mathsf{CDF}_\epsilon(x, y)$ to $P(X \leq x | Y = y)$. Then $\mathsf{PMF}_{2\epsilon}(x, y) := \mathsf{CDF}_\epsilon(x, y) - \mathsf{CDF}_\epsilon(x-1, y)$ is a $2\epsilon$ additive approximation to $P(X = x | Y = y)$.
            % \item \textit{Relative appoximation. }Say we can compute a relative $\epsilon$ approximation $\mathsf{CDF}'_\epsilon(x, y)$ to $P(X \leq x | Y = y)$. Then $\mathsf{PMF}_{2\epsilon}(x, y) := \mathsf{CDF}_\epsilon(x, y) - \mathsf{CDF}_\epsilon(x-1, y)$ is a $2\epsilon$ additive approximation to $P(X = x | Y = y)$.
        \end{enumerate}
    \item \textbf{Sampling is harder than probabilistic PMF computation up to additive error.} Say that it is possible to sample with pointwise error $\epsilon / 2$ from $P(X = \cdot | Y = y)$. Let $Q$ be the exact distribution which can be sampled from, which has pointwise error $\leq \epsilon / 2$ from the posterior.  Consider an algorithm which generates $N$ independent samples $x_i \sim ~$ and computes $\hat{p} := \frac{1}{N} \sum_{i=1}^N 1_{x_i = x}$.
    By the Hoeffding theorem, since $\mathbb{E}[\hat{p}] = Q(x)$, $\Pr[|\hat{p} - Q(x)| \geq \epsilon / 2] \leq 2e^{-\epsilon^2/(2N)}$. Thus if $N = 100/\epsilon^2$, $\Pr[|\hat{p} - Q(x)| \geq \epsilon / 2] << 1/3$.
    Because $|Q(x) = P(X = x | Y = y)| < \epsilon/2$, this means that
    $\Pr[|\hat{p} - P(X = x | Y = y)| > \epsilon] << 1/3$.
    Thus it is possible to compute an $\epsilon$ approximation to PMF at a cost $O(1/\epsilon^2)$ times the cost of performing approximate pointwise sampling.
    Therefore a polynomial time approximate sampling algorithm implies the existance of a polynomial time additive PMF approximation algorithm.
\end{enumerate}

% \section{Posterior inference on typical-case observations}

\section{Background for the main results}

\subsection{Probabilistic graphical models and inference problems}
\begin{defn}
A \textbf{probabilistic graphical model on binary variables} is a tuple $(V, E, P)$, where $V$ is an ordered, finite set of variables $V = \{v_1, \dots, v_n\}$, $E$ is a set of directed edges between the variables, and $P$ is a \textit{conditional probability table}.
The directed graph $(V, E)$ must be acyclic.
For $v \in V$, $\Pa(v)$ denotes the set of parent variables of $v$: $\Pa(v) = \{u : (u \mapsto v) \in E\}$.
Given any assignment $a_{\Pa(v)} \in \{0, 1\}^{|\Pa(v)|}$ to the parent variables of $v$, the conditional probability table $P$ stores value $P(v = \cdot ; a_{\Pa(v)})$, which is a probability vector $[p_{v=0}, p_{v=1}]$ in $\mathbb{R}^2$.
\end{defn}

A general probabilistic graphical model lifts the restriction that each variable $v_i$ is binary, and allows it to have arbitrary finite domain.
In this report, I will focus on binary probabilistic graphical models. Because a variable with a domain of size $k$ can be represented using $\log k$ binary variables, all the results in this case carry to the general case, except those which restrict the sizes of sets of variables under consideration.
Henceforth, the phrase ``probabilistic graphical model'' should be understood as a graphical model on binary variables.

Given a graphical model $(P, E, V)$, we can define a joint distribution on all the variables in $V$, with probability mass function
$$
P(a) = \prod_{v_i \in V}{P(v_i = a_i ; a_{\Pa(v_i)})} \quad \forall a \in \{0, 1\}^{|V|}
$$
where $a_{\Pa(v_i)}$ is the assignment to the parent variables of $v_i$ in $a$.
I will often write $P$ to refer to the whole graphical model, the joint distribution on all its variables, and also marginal and conditional distributions on subsets of its variables.

\begin{defn}
An \textbf{inference problem} consists of a graphical model $(V, E, P)$, a set of \textit{observed variables} $Y \subseteq V$, a set of \textit{query variables} $X \subseteq V$, and an assignment $y \in \{0, 1\}^{|Y|}$ to the observed variables such that $P(Y = y) > 0$.
\end{defn}
The goal of an inference problem is to compute some piece of information about the posterior distribution $P(X = \cdot | Y = y)$, which is a probability distribution on $\{0, 1\}^{|X|}$.

\begin{defn}
An \textbf{inference problem schema} is the tuple $I = (V, E, P, X, Y)$ as in an inference problem, but not fixing an assignment $y$ to the observed variables.
\end{defn}

\subsection{Worst and typical case inference algorithms}

\begin{defn}
A \textbf{deterministic, worst-case additive PMF approximation algorithm with tolerance $\epsilon$} is a Turing machine $A$ which on input
$(I, y, x)$, where $I$ is any inference problem schema, $y$ is any assignment to the observed variables, and $x$ is an assignment to the query variables, outputs a rational number $A(I, y, x)$ such that
\begin{equation} \label{eq:worst_case}
|A(I, y, x) - P(X = x | Y = y)| < \epsilon
\end{equation}
\end{defn}
\begin{defn}
A \textbf{probabilistic, worst-case additive PMF approximation algorithm with tolerance $\epsilon$} is a probabilistic Turing machine $A$ which for every $I, y, x$, satisfies condition~\ref{eq:worst_case} with probability $\geq 2/3$.
\end{defn}

In 1993, Dagum and Luby \cite{dagum1993} showed that if there exists a deterministic worst-case additive PMF approximation algorithm with tolerance $< 1/2$, and it has polynomial runtime, then $\P = \NP$.
Further, if a probabilistic polynomial-time worst-case additive PMF approximation algorithm exists with tolerance $< 1/2$, then $\NP \subseteq \RP$.

Probabilistic graphical models are typically used to model aspects of the world.
That is, each variable in $V$ represents some aspect of the world; $Y$ represents a set of values which we have observed; and $X$ represents a set of values which we wish to infer.
In this setting, the probability distribution $P$ is a description of our beliefs about how probable different joint outcomes of events in the world are.
Therefore, given a graphical model $P$ in which we must do inference, it may be acceptable to us if there is exist assignments $y$ under which computing the posterior distribution is very expensive, so long as these instances are extremeley rare.
Since we have a probability distribution $P$ on hand which ought to roughly correspond to the distribution of $y$ values which will occur in the world, and on which we will have to run inference, a natural notion of ``rare'' is available.
Say there is a small set of observation assignments $\mathcal{Y}_\text{hard} \subseteq \{0, 1\}^{|Y|}$ such that $P(\mathcal{Y}_\text{hard}) < \rho$ for very small $\rho$ (e.g. $\rho = 0.00001$), such that for all $y \notin \mathcal{Y}_\text{hard}$, we can compute the posterior distribution $P(X = \cdot | Y = y)$ efficiently.
Then we can say that inference is easy in the typical case, and for many purposes this is sufficient.

% In fact, Dagum and Luby's construction of a worst-case inference problem $I$ involves selecting an observed assignment $y$ to a set $Y$ of one variable ($|Y| = 1$) which has extremely low marginal probability: $P(Y = y) << 1$.
% Theorem~\ref{} later in this report shows that for every inference problem schema $(P, V, E, X, Y)$ with $|Y| = 1$, efficient inference is possible on typical case observations.
% This indicates that Dagum and Luby's strategy for proving the hardness of inference in the worst case does not directly carry through to showing the hardness of inference with typical-case observations.

% \begin{defn}
% A \textbf{deterministic, typical-case relative PMF approximation algorithm with tolerances $(\epsilon, \rho)$} is a Turing machine $A$ which accepts inputs of the form
% $(I, y, x)$, where $I$ is any inference problem schema, $y$ is any assignment to the observed variables, and $x$ is an assignment to the query variables, and outputs a rational number $A(I, y, x)$ with the following property.
% For any graphical model $(V, E, P)$ and any subset $Y \subseteq V$,
% there exists a ``typical set'' $\mathcal{Y}_\text{easy} \subseteq Y$ such
% that $$P(Y \in \mathcal{Y}_\text{easy}) > 1 - \rho$$ and
% for all $X \subseteq V$, any assignment $x$ to $X$,
% and any $y \in \mathcal{Y}_\text{easy}$,
% $$
% A(I, y, x) / P(X = x | Y = y) \in (\frac{1}{1 + \epsilon}, 1 + \epsilon)
% $$
% That is, on all but a small fraction $\rho$ of $y$ values, the algorithm can outputs an $\epsilon$ relative approximation to the posterior PMF value $P(X = x | Y = y)$,
% for any query variables $X$ and any query assignment $x$.
% \end{defn}

\begin{defn} \label{def:typical_case_add_alg}
A \textbf{deterministic, typical-case additive PMF approximation algorithm with tolerances $(\epsilon, \rho)$} is a Turing machine $A$ which accepts inputs of the form
$(I, y, x)$, where $I$ is any inference problem schema, $y$ is any assignment to the observed variables, and $x$ is an assignment to the query variables, and outputs a rational number $A(I, y, x)$ with the following property.
For any inference schema $I$ and any value $x$,
$$
\Pr_{y \sim P(Y = \cdot)}[|A(I, x, y) - P(X = x | Y = y)| \geq \epsilon] < \rho
$$
Given such an algorithm $A$, a given inference schema $I$, and a value $x$, I will write $\Ygood$ to denote the set
$$
\Ygood := \{y : |A(I, x, y) - P(X = x | Y = y)| < \epsilon\}
$$
Note that $P(\Ygood) > 1 - \rho$.
\end{defn}
\begin{defn}
A \textbf{probabilistic, typical-case additive PMF approximation algorithm with tolerances $(\epsilon, \rho)$} is a probabilistic Turing machine $A$ which accepts inputs $(I, y, x)$ as above, such that for any inference schema $I$ and any value $x$, there exists a set $\Ygood \subseteq \{0, 1\}^{|Y|}$ where $P(\Ygood) > 1 - \rho$ and
$$
y \in \Ygood \implies \Pr[|A(I, x, y) - P(X = x | Y = y)| < \epsilon] > 2/3
$$
where the probability is taken over the randomness of the algorithm.
\end{defn}

In this report, I prove a new result showing that if either a deterministic or probabilistic typical-case additive PMF approximation algorithm exists with tolerances $\epsilon < 1/2$, $\rho < 1/4$, then one-way functions do not exist (Theorem~\ref{thm:main}).
This hardness result suggests that typical-case inference is computationally difficult, and it is not merely the worst-case nature of the observations considered in Dagum and Luby's reduction which made inference difficult in their setting.
Due to the typical-case formulation studied here, a different proof strategy is needed to show this hardness result.

\subsection{One-way functions and pseudorandom generators}
Proving the hardness of a computational problem $C$ is often done by reducing from an $\NP$-hard problem like $\mathsf{3SAT}$ to problem $C$, thereby showing that if $C$ could be solved in polynomial time, $\P = \NP$.
However, problems like $\mathsf{3SAT}$ are stated in terms of behavior on all, and thus worst-case, inputs.
Therefore, to prove the hardness of a computational problem on typical-case inputs, it is preferable to reduce to a hardness conjecture stated directly in terms of typical-case behavior.

In this report I will reference two such conjectures, which are known to be related.
The first conjecture is the existance of \textit{one-way functions}, functions which can be efficiently computed, but not efficiently inverted for the majority of inputs.
It is widely believed that such functions exist \cite{}, as there are a number of functions like multiplication of prime numbers, for which no inversion algorithms are known which are efficient in the typical case.
Such functions are widely used in public-key cryptography.

\begin{defn}{(Arora and Barak Def. 9.4)} \label{def:oneway}
A \textbf{one-way function} $f$ is a function $f : \{0, 1\}^* \to \{0, 1\}^*$ such that $f$ can be computed in polynomial time, and for every probabilistic polynomial time algorithm $A$, for every $c \in \mathbb{R}$,
\begin{equation} \label{eq:oneway}
n^c \cdot \Pr_{x \sim \text{Uniform}(\{0, 1\}^n)}[A(f(x), 1^n) \in f^{-1}(f(x))] \underset{n \to \infty}{\to} 0
\end{equation}
where $f^{-1}(f(x))$ is the set $\{x' \in \{0, 1\}^* : f(x') = f(x)\}$.
\end{defn}

The second conjecture is the existance of \textit{secure pseudorandom generators}, which are functions which take a short random seed and expand it into a long string which is indistinguishable from a truly random string.
This is known to follow from the existence of one-way functions, and this weaker conjecture is all the is needed for the main result of this report.
Specifically, I consider PRGs which are secure against all polynomial-time adversaries, once the strings being generated are sufficiently long.

\begin{defn}{(Weakened variant of Arora and Barak Def. 9.8)}
A \textit{secure pseudorandom generator} (PRG) is a polynomial time computable function $\{0, 1\}^* \to \{0, 1\}^*$ such that $|G(x)| = |l(|x|)|$ for some function $l : \mathbb{N} \to \mathbb{N}$, such that for every probabilistic polynomial time algorithm $A$,
\begin{equation} \label{eq:prg}
|\Pr_{s \sim \text{Uniform}(\{0, 1\}^n)}[A(G(s)) = 1] - \Pr_{y \sim \text{Uniform}(\{0, 1\}^{l(n)})}[A(y) = 1]| \underset{n \to \infty}{\to} 0
\end{equation}
The function $l$ is called the stretch of the PRG.
% I say the stretch is \textit{superlinear} if $l(n) / n \to \infty$ as $n \to \infty$.
\end{defn}
This definition is weaker than the definition given in Arora and Barak, as it only requires the expression in eq.~\ref{eq:prg} to tend to zero, rather than to zero at a superpolynomial rate, as in eq.~\ref{eq:oneway}, and as in Arora and Barak's definition of a secure PRG.
The reduction in this report shows that the existence of a secure PRG, as defined here, with superlinear stretch implies the non-existence of typical-case inference algorithms with certain tolerances.
The existance of secure PRGs as defined in Arora and Barak is a strictly stronger statement than the existance of secure PRGs as defined here, and their PRGs are instances of secure PRGs as defined here.

It is known that the existence of one-way functions implies the existence of secure pseudorandom generators.
Thus, to the extent that it is believed that one-way functions exist, it is also believed that secure pseudorandom generators exist.
\begin{prop}{(Arora and Barak Thm. 9.9)} \label{prop:oneway_to_prg}
If there exists a one-way function, then there exists a secure pseudorandom generator with stretch $l(n) = n^c$.
\end{prop}
The reason I include the superpolynomial convergence rate in Def.~\ref{def:oneway} is to ensure that this theorem goes through.
As far as I am aware, it may be that given my weaker definition of a secure PRG, a weaker definition of one-way function would also suffice to imply the existance of such PRGs, but I have not verified this.

\section{Main result}
% \begin{defn}
% I call a function $l(n) : \mathbb{N} \to \mathbb{N}$ a well-behaved stretch function iff $\lim_{n \to \infty}[l(n) - n] = \infty$ and $l$ is invertible.
% \end{defn}

\begin{thm} \label{thm:main}
If there exists a polynomial-time typical-case additive PMF approximation algorithm $A$ with tolerances $\epsilon < \frac{1}{2}$, $\rho < \frac{1}{4}$,
then there does not exist a secure pseudorandom generator with an invertible stretch function $l$ such that $\lim_{n \to \infty}[l(n) - n] = \infty$.
This holds whether $A$ is deterministic or probabilistic.
\end{thm}

\begin{cor}
If there exists a polynomial-time, deterministic, typical-case additive PMF approximation algorithm with tolerances $\epsilon < \frac{1}{2}$, $\rho < \frac{1}{4}$,
then one-way functions do not exist.
\end{cor}
\noindent The corollary follows because if one-way functions exist, by Proposition~\ref{prop:oneway_to_prg}, there exists a secure PRG with stretch $l(n) = n^2$.

\begin{proof}{(Theorem~\ref{thm:main})}
For contradiction, suppose $A$ is a deterministic polynomial-time typical-case additive PMF approximation algorithm with tolerances $\epsilon < \frac{1}{2}$ and $\rho < \frac{1}{4}$.
(The case where $A$ is probabilistic will be covered at the end of the proof.)
Let $\delta > 0$ be s.t. $\epsilon < \frac{1}{2} - \delta$.
Suppose $G$ is a secure PRG with invertible stretch function $l(n)$ s.t. $\lim_{n \to \infty} [l(n) - n] = \infty$.
Note that $l^{-1}$ is computable in $\text{poly}(n)$ time, because given $m$, one can iterate through the values $n = 1, 2, \dots, m$ to find when $l(n) = m$.

\medskip
\noindent \textbf{Proof outline.}
I will construct a Turing machine $B$ which can distinguish the distributions $\text{Uniform}(\{0, 1\}^n) \circ G^{-1}$ and $\text{Uniform}(\{0, 1\}^{l(n)})$ for all $n > N$, where $N$ is a constant.  This contradicts that $G$ is a secure PRG.

Given input $y \in \{0, 1\}^{l(n)}$,
Turing machine $B$ will guess whether it was sampled from the pseudo-random generator, or from the uniform on $\{0, 1\}^{|y|}$.
If a string $y$ is given such that $|y|$ is not in the range of $l$, then $B$ can immediately reject.
Otherwise, $B$ will compute $n = l^{-1}(|y|)$ to find the seed length needed for $G$ to produce $y$.

Second, $B$ will construct the description of an inference schema $I = (P, V, E, X, Y)$ where $|Y| = l(n)$ and $|X| = 1$, such that if $n > N$,
$$
y' \in G(\{0, 1\}^n) \implies P(X = 1 | Y = y') > 1 - \delta \quad (*)
$$
and
$$
y' \notin G(\{0, 1\}^n) \implies P(X = 1 | Y = y') = 0 \quad (**)
$$
Third, $B$ will compute $a \gets A(I, 1, y)$.
If $a < 1/2$, $B$ will output 0; otherwise $B$ will output 1.
I will first show that this implies that on typical $y$ values,
$B$ exactly decides whether $y \in \text{range}(G)$.
Specifically, there is a set $\Ygood \subseteq \{0, 1\}^{l(n)}$ with $P(\Ygood) > 3/4$ such that
$y \in \Ygood \implies B(y) = 1_{y \in \text{range}(G)}$.
Using this,
I will then show that, because we can guarantee $P(y \in \Ygood) > 3/4 = 1 - \rho$,
this implies that there exists a $\gamma > 0$ such that
$$
|\Pr_{s \sim \text{Uniform}(\{0, 1\}^n)}[B(G(s)) = 1] - \Pr_{\by \sim \text{Uniform}(\{0, 1\}^{l(n)})}[B(\by) = 1]| \geq \gamma \quad (***)
$$
for all sufficiently large $n$, contradicting that $G$ is a secure pseudorandom generator.
% This part of the proof will involve a case analysis regarding how the values in $\mathcal{Y}_\text{easy}$ are distributed among range of $G$, and its complement.

I now proceed to complete the proof by (1) proving that $B$ can construct an inference schema with properties $(*)$ and $(**)$, and (2) proving that $(***)$ holds.

\medskip
\noindent \textbf{Construction of the inference schema.}
Let $(P, V, E)$ be the probabilistic graphical model which implements the following process.
$P$ samples $s = s_1 s_2 \dots s_n$ uniformly at random from $\{0, 1\}^n$.
$P$ samples $\bar{y} = \bar{y}_1 \bar{y}_2 \dots \bar{y}_{l(n)}$ uniformly at random from $\{0, 1\}^{l(n)}$.
$P$ samples $x$ uniformly at random from $\{0, 1\}$.
If $x = 0$, $P$ computes $y = \bar{y}$.
Otherwise, $P$ computes $y = G(s)$.
Clearly, writing a graphical model which does the sampling and multiplexing steps can be done in polynomial time.
And writing out the part of the graphical model which computes $G(s)$ can be done in polynomial time in $n$ using the Cook-Levin reduction for writing a circuit which implements the same behavior as the Turing machine for $G$, on inputs of length $n$.

\medskip
\noindent \textbf{Analysis of the posteriors (proof of $(*)$ and $(**)$).}
First, note that if $y \notin \text{range}(G)$,
$$
P(X = 1 | Y = y) = \frac{P(X = 1, Y = y)}{P(Y = y)} = \frac{0}{P(Y = y)} = 0
$$
because it is impossible for $P$ to sample $x = 1$ yet output a value not in the range of $G$.
This proves $(**)$.

Now, say $y \in \text{range}(G)$.
Let $m = |G^{-1}(y)|$, the number of seeds in $\{0, 1\}^n$ that get mapped to $y$.
Then
$$
P(X = 1 | Y = y) = \frac{P(X = 1, Y = y)}{P(X = 0, Y = y) + P(X = 1, Y = y)}
= \frac{
    \frac{1}{2} \frac{m}{2^n}
}{
    \frac{1}{2} \frac{1}{2^{l(n)}} + \frac{1}{2} \frac{m}{2^n}
}
$$
The numerator here is $P(X = 1, Y = y) = \frac{1}{2} \frac{m}{2^n}$ 
because $X = 1$ with probability $\frac{1}{2}$, and given that $X = 1$, we will have $Y = y$ iff the seed $s$ is in $G^{-1}(y)$, which occurs with probability $\frac{m}{2^n}$.
The denominator contains the term $P(X = 0, Y = y) = \frac{1}{2} \frac{1}{2^{l(n)}}$ because there is a $1/2$ probability that $X = 0$, and if it is $0$, $Y = y$ only if one of the $2^{l(n)}$ equally probable values in $\{0, 1\}^{l(n)}$ is chosen as $\bar{y}$.

Simplifying this, 
$$
P(X = 1 | Y = y) = \frac{
    m/2^n
}{
    1/2^{l(n)} + m/2^n
}
$$
so
$$
P(X = 0 | Y = y) = \frac{
    1/2^{l(n)}
}{
    1/2^{l(n)} + m/2^n
} = \frac{1}{1 + m 2^{l(n) - n}}
$$
Since $2^{l(n) - n} > 0$, this expression decreases in $m$.
Since $y \in \text{range}(G)$, $m \geq 1$.
Thus this expression is maximized when $m = 1$.
Therefore, for all $m$,
$$
P(X = 0 | Y = y) \leq \frac{1}{1 + 2^{l(n) - n}} < \frac{1}{2^{l(n) - n}}
$$
Let $N_1$ be an integer such that
$n > N_1 \implies l(n) - n > \log(1/\delta)$.
Then $n > N_1 \implies 2^{l(n) - n} > 1/\delta$,
so for all such $n$,
$$
P(X = 0 | Y = y) < \delta
$$
and thus
$$
P(X = 1 | Y = y) > 1 - \delta
$$
This proves $(*)$.

\medskip
\noindent \textbf{Proof that on $\Ygood$, $B$ exactly identifies $\text{range}(G)$.}
Let $\Ygood$ be the good set of observations for inference schema $I$ constructed above, and assignment $x = 1$, as defined in Definition~\ref{def:typical_case_add_alg}.
Then if the given $y$ satisfies $y \in \Ygood$, $|A(I, x, y) - P(X = x | Y = y)| < \epsilon < \frac{1}{2} - \delta$.
Thus if $y \notin \text{range}(G)$, by $(**)$, $|A(I, x, y) - 0| < \frac{1}{2} - \delta$ so $A(I, x, y) < 1/2$.
And if $y \in \text{range}(G)$ but $A(I, x, y) < 1/2$, by $(*)$ we would have $|P(X = 1 | Y = y) - A(I, x, y)| \geq |(1 - \delta) - 1/2| \geq 1/2 - \delta > \epsilon$, so it must be the case that $A(I, x, y) > 1/2$.
That is,
$$
y \in \Ygood \implies [y \notin \text{range}(G) \implies A(I, x, y) < 1/2 \wedge y \in \text{range}(G) \implies A(I, x, y) > 1/2]
$$
Thus for $y \in \Ygood$, algorithm $B$ exactly decides whether $y \in \text{range}(G)$: $y \in \Ygood \implies B(y) = 1_{y \in \text{range}(G)}$.

\medskip
\noindent \textbf{Proof that $B$ identifies outputs from the PRG with nontrivial probability (proof of $(***)$).}
In this section I will write $\Pr_s$ as shorthand for $\Pr_{s \sim \text{Uniform}(\{0, 1\}^n)}$ and $\Pr_{\bar{y}}$ as shorthand for $\Pr_{\bar{y} \sim \text{Uniform}(\{0, 1\}^{l(n)})}$.

The goal of this section is to establish that there exists a $\gamma > 0$ such that
$$
|
\Pr_s[B(G(s)) = 1] - \Pr_{\bar{y}}[B(\bar{y}) = 1]
| \geq \gamma
$$
Let $p_s := \Pr_s[B(G(s)) = 1]$ and $p_\by := \Pr_{\bar{y}}[B(\bar{y}) = 1]$.
Let $p_{s, 1} := \Pr_s[B(G(s)) = 1 \wedge G(s) \in \Ygood]$,
$p_{s, 2} := \Pr_s[B(G(s)) = 1 \wedge G(s) \notin \Ygood]$,
$p_{\by, 1} = \Pr_{\bar{y}}[B(\bar{y}) = 1 \wedge \by \in \Ygood]$,
and
$p_{\by, 2} = \Pr_{\bar{y}}[B(\bar{y}) = 1 \wedge \by \notin \Ygood]$.
Observe that
$p_s = p_{s, 1} + p_{s, 2}$ and $p_\by = p_{\by, 1} + p_{\by, 2}$.
By the triangle inequaltiy,
\begin{equation} \label{eq:triangle_inequality_application}
|p_s - p_\by| = |p_{s, 1} + p_{s, 2} - p_{\by, 1} - p_{\by, 2}| \geq |p_{s, 1} - p_{\by, 1}| - |p_{s, 2} - p_{\by, 2}|
\end{equation}

We have
\begin{multline} \label{eq:terms_ybad}
|p_{s, 2} - p_{\by, 2}| = 
|\Pr_{s}[G(s) \notin \Ygood] \Pr_s[B(G(s)) = 1 | G(s) \notin \Ygood]
 - \Pr_\by[\by \notin \Ygood] \Pr_\by[B(\by) = 1 | \by \notin \Ygood]|
\\
\leq \max(\Pr_s[G(s) \notin \Ygood], \Pr_\by[\by \notin \Ygood])
\end{multline}

We also have
\begin{multline} \label{eq:terms_ygood}
p_{s, 1} - p_{\by, 1} =
\Pr_s[B(G(s)) = 1 \wedge G(s) \in \Ygood] - \Pr_\by[B(\by) = 1 \wedge \by \in \Ygood]
 \\
= 
\Pr_s[G(s) \in \text{range}(G) \wedge G(s) \in \Ygood] -
\Pr_\by[\by \in \text{range}(G) \wedge \by \in \Ygood]
\\
= \Pr_s[G(s) \in \Ygood] - \Pr_\by[\by \in \text{range}(G) \wedge \by \in \Ygood] \\
\geq \Pr_s[G(s) \in \Ygood] - \Pr_\by[\by \in \text{range}(G)] 
= \Pr_s[G(s) \in \Ygood] - 2^n/2^{l(n)}
\end{multline}
The second equality here follows from the fact established above, that for $y \in \Ygood$, algorithm $B$ exactly decides whether $y \in \text{range}(G)$.

We now need to bound $\Pr_s[G(s) \in \Ygood]$ and $\Pr_\by[\by \in \Ygood]$.
Observe that
$$
P(\Ygood) = \frac{1}{2}\Pr_s[G(s) \in \Ygood] + \frac{1}{2}\Pr_\by[\by \in \Ygood]
$$
because under the model $P$, $y$ is set equal to $G(s)$ half the time and equal to $\by$ the other half of the time.
Since each of these probability terms are no greater than $1$, we have
\begin{equation} \label{eq:branch_probs_ygood}
\Pr_s[G(s) \in \Ygood] \geq 2P(\Ygood) - 1;
\quad
\Pr_\by[\by \in \Ygood] \geq 2P(\Ygood) - 1        
\end{equation}
By subtracting each side of these inequalities from 1, we also obtain
\begin{equation} \label{eq:branch_probs_ybad}
\Pr_s[G(s) \notin \Ygood] \leq 2 - 2P(\Ygood);
\quad
\Pr_\by[\by \notin \Ygood] \leq 2 - 2P(\Ygood)
\end{equation}

Combining equations \ref{eq:terms_ybad} and \ref{eq:branch_probs_ybad}, we get
\begin{equation}
|p_{s, 2} - p_{\by, 2}| \leq 2 - 2P(\Ygood)    
\end{equation}
and combining equations \ref{eq:terms_ygood} and \ref{eq:branch_probs_ygood}, we get
\begin{equation} \label{eq:term1s_err_bound}
|p_{s, 1} - p_{\by, 1}| \geq 2P(\Ygood) - 1 - 2^{n - l(n)}    
\end{equation}
Plugging in these bounds to equation~\ref{eq:triangle_inequality_application}, we obtain
\begin{equation} \label{eq:final_ps_py_bound}
|p_s - p_\by| \geq
2P(\Ygood) - 1 - 2^{n - l(n)}
- (2 - 2P(\Ygood))
= 4 P(\Ygood) - 3 - 2^{n - l(n)}
\end{equation}
Thus, 
$$
P(\Ygood) \geq \frac{3}{4} + \frac{1}{4 \cdot 2^{l(n) - n}} + \frac{1}{4}\gamma
\implies |p_s - p_\by| \geq \gamma
$$
Since $l(n) - n \to \infty$, the term $\frac{1}{4 \cdot 2^{l(n) - n}} \to 0$,
so there exists $N_2$ such that for all $n > N_2$,
$$
P(\Ygood) > \frac{3}{4} \implies \exists \gamma > 0 \text{ s.t. } |\Pr_s[B(G(s)) = 1] - \Pr_{\bar{y}}[B(\bar{y}) = 1]| \geq \gamma
$$
Finally, it suffices to take $N = \max(N_1, N_2)$.

\medskip
\noindent
\textbf{Extending the proof to the case where the inference algorithm $A$ is probabilistic.}
This extension is fairly straightforward; we simply need to track several additional terms in the analysis, to control the probability that algorithm $B$ fails to indicate whether $y \in \text{range}(G)$ for a value $y \in \Ygood$.
Since we can upper-bound this probability arbitrarily tightly by boosting the probabilistic version of algorithm $B$ through replication, the ultimate conclusion is the same as before.

Say that the inference algorithm $A(I, x, y)$ is probabilistic.
Write $A(I, x, y, r)$ to denote a run of algorithm $A$ that uses internal random bits $r$.
By saying $A$ is a probabilistic typical-case additive-error PMF approximation algorithm, we mean that for $y \in \Ygood$, we have
$$
\Pr_r [|A(I, x, y, r) - P(X = x | Y = y)| \geq \epsilon] < 1/3
$$
In the procedure described above, the only place where algorithm $B$ uses algorithm $A$ is to check if $P(X = 1 | Y = y)$ is greater than $1/2$.
I will write $B(y, r)$ for a call to $B$ that uses random bits $r$ when calling $A$.
Our preceding analysis shows that for $y \in \Ygood$,
$$
|A(I, 1, y, r) - P(X = 1 | Y = y)| < \epsilon \implies  B(y, r) = 1_{y \in \text{range}(G)}
$$
Thus for $y \in \Ygood$,
$$
\Pr_r [B(y, 1) \neq 1_{y \in \text{range}(G)}] < 1/3
$$
By calling $B$ $O(k)$ times with different random $r$, and taking the most frequent output, we can obtain an algorithm $B^*$, comsuming randomness $r^*$, where for $y \in \Ygood$,
$$
\Pr_{r^*} [B^*(y, r^*) \neq 1_{y \in \text{range}(G)}] < 1/2^k
$$
% For convenience I will henceforth relabel $B$ and $r$ to refer to the boosted variants of the algorithm: $B := B^*$, $r := r^*$.

Except for the final section dedicated to proving statement $(***)$, the preceding proof remains essentially unchanged.
We must, however, redo part of the analysis in the final section, replacing the old deterministic algorithm $B$ with our new stochastic algorithm $B^*$.
Much of the analysis remains unchanged, except that
the expressions $\Pr_s$ and $\Pr_\by$ should be understood to also close over the randomness $r^*$.
The first place where the analysis diverges nontrivially is in equation~\ref{eq:terms_ygood}.

To do the new version of the analysis, I will introduce the following notation. For $y \in \Ygood$, let $\Rgood^y$ be the set of random strings $r^*$ such that $B^*(y, r^*) = 1_{y \in \text{range}(G)}$,
and for $y \notin \Ygood$ let $\Rgood^y$ be the set of all bitstrings $r^*$.

Using this, in place of Equation~\ref{eq:terms_ygood}, we now have

\begin{multline} \label{eq:terms_ygood_stochastic}
    p_{s, 1} - p_{\by, 1} =
    \Pr_{s, r^*}[B(G(s)) = 1 \wedge G(s) \in \Ygood] - \Pr_{\by, r^*}[B(\by) = 1 \wedge \by \in \Ygood]
     \\
    =
    \Pr_{s, r^*}[G(s) \in \text{range}(G) \wedge G(s) \in \Ygood \wedge r^* \in \Rgood^{G(s)}] + \Pr_{s, r^*}[B(G(s)) = 1 \wedge G(s) \in \Ygood \wedge r^* \notin \Rgood^{G(s)}] \\
    - (\Pr_{\by, r^*}[\by \in \text{range}(G) \wedge \by \in \Ygood \wedge r^* \in \Rgood^\by] + \Pr_{\by, r^*}[B(\by) = 1 \wedge \by \in \Ygood \wedge r^* \notin \Rgood^\by]) \\
    \geq \Pr_{s, r^*}[G(s) \in \text{range}(G) \wedge G(s) \in \Ygood \wedge r^* \in \Rgood^{G(s)}] \\
    - (\Pr_{\by, r^*}[\by \in \text{range}(G) \wedge \by \in \Ygood \wedge r^* \in \Rgood^\by] + \Pr_{\by, r^*}[B(\by) = 1 \wedge \by \in \Ygood \wedge r^* \notin \Rgood^\by]) \\
    \geq (1 - \frac{1}{2^k}) \Pr_{s, r^*}[G(s) \in \text{range}(G) \wedge G(s) \in \Ygood] - \Pr_{\bar{y}, r^*}[\by \in \text{range}(G)] - \Pr_{\by, r^*}[r^* \notin \Rgood^\by] \\
    \geq (1 - \frac{1}{2^k}) \Pr_{s}[G(s) \in \Ygood] - 2^n/2^{l(n)} - 1/2^k
    % + \Pr_{s, r^*}[r^* \notin \Rgood^{G(s)} \wedge G(s) \in \Ygood]
    % \Pr_\by[\by \in \text{range}(G) \wedge \by \in \Ygood]
    % \\
    % = \Pr_s[G(s) \in \Ygood] - \Pr_\by[\by \in \text{range}(G) \wedge \by \in \Ygood] \\
    % \geq \Pr_s[G(s) \in \Ygood] - \Pr_\by[\by \in \text{range}(G)] 
    % = \Pr_s[G(s) \in \Ygood] - 2^n/2^{l(n)}
\end{multline}
Rewriting inequality~\ref{eq:term1s_err_bound} using this new bound yields
\begin{equation}
|p_{s, 1} - p_{\by, 1}| \geq (1 - \frac{1}{2^k})(2P(\Ygood) - 1) - 2^{n - l(n)} - 1/2^k 
\end{equation}
Equation~\ref{eq:final_ps_py_bound} becomes
\begin{multline}
|p_s - p_\by| \geq (1 - \frac{1}{2^k})(2P(\Ygood) - 1) - 2^{n - l(n)} - 1/2^k - (2 - 2P(\Ygood)) \\
= 4P(\Ygood) - 3 - 2^{n - l(n)} - \frac{2P(\Ygood)}{2^k}
\geq 4P(\Ygood) - 3 - 2^{n - l(n)} - \frac{2}{2^k}
\end{multline}
where the last inequality follow from the fact that $P(\Ygood) \leq 1$.
Therefore
\begin{equation} \label{eq:pygood_implication_stochastic}
P(\Ygood) \geq \frac{3}{4} + \frac{1}{4}(\frac{1}{2^{l(n) - n}} + \frac{2}{2^k}) + \frac{1}{4} \gamma \implies |p_s - p_\by| \geq \gamma
\end{equation}
Since we in fact have $P(\Ygood) > \frac{3}{4}$ with strict inequality, let $\eta > 0$ be such that $P(\Ygood) \geq \frac{3}{4} + \eta$.
Choose $N_2, k$ large enough so that $n \geq N_2 \implies \frac{1}{2^{l(n) - n}} + \frac{2}{2^k} < \eta/2$, and set $\gamma = 2\eta$.
Because $\rho$ is a property of algorithm $A$, this choice of $k$ is independent of the length of the string $y$ input to algorithm $B$, so $k$ is a constant for the purposes of characterizing the complexity of algorithm $B$.
Thus setting $k$ to have this value does not affect the assessment that $B$ is a polynomial-time algorithm.
Then (\ref{eq:pygood_implication_stochastic}) holds, so for all $n > N := \max(N_1, N_2)$,
$$
\exists \gamma > 0 \text{ s.t. } |\Pr_{s, r^*}[B(G(s)) = 1] - \Pr_{\by, r^*}[B(\by) = 1]| \geq \gamma
$$

\end{proof}

% Finally, here is a proof of the minor lemma used at the beginning of the proof of Theorem~\ref{thm:main}.
% \begin{lem} \label{lem:bijective_stretch}
% If there exists a secure PRG $G$ with stretch $l(n)$ such that $\lim_{n \to \infty} [l(n) - n] = \infty$,
% then
% there exists a PRG $G'$ with superlinear stretch $l'$ such that $l'$ is a bijection and such that  $(l')^{-1}$ can be computed in polynomial time.
% \end{lem}
% \begin{proof}
% For any $k \in \mathbb{N}$, let $N_k$ be the smallest element of $\mathbb{N}$ such that $n \geq N_k \implies l(n) - n > k$.
% For any $n \in \mathbb{N}$, let $k_n$ be the smallest $k$ such that $n \geq N_k$.
% Let $l'(n) = n + k_n$.
% Observe that $l'$ is strictly increasing and hence a bijection.
% Its inverse can be computed as follows.
% Consider output $m$ of $l'$.
% For each value $n = 1, 2, \dots$, compute $l'(n)$ and check if it equals $m$.
% Output $n$ once this is the case.
% Since $m > n$, and this process terminates in at most $n$ steps,
% this process can be done in polynomial time in $m$.

% Finally, take $G'(x) := G(x)_{1:l'(n)}$, where $y_{1:t}$ denotes the first $t$ bits of $y$.
% If an algorithm could distinguish the outputs of $G'$ from uniform, then it could certainly distinguish the outputs of $G$ from uniform by only considering the first $l'(n)$ bits.
% Thus $G'$ is also a secure pseudorandom generator.
% % Since $l(n)/n \to \infty$, there exists $N$ such that $l(n) > 2n$ for all $n \geq N$.
% % Let $l'$
% \end{proof}

% \printbibliography

\end{document}