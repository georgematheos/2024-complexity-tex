\documentclass{article}
\usepackage{amsmath}
% \usepackage{fullpage}
\usepackage{amsmath,amssymb,verbatim}
% \usepackage{fullpage}
\usepackage{enumerate}
\usepackage{xcolor}
\renewcommand{\P}{\mathbf{P}}
\newcommand{\NP}{\mathbf{NP}}
\newcommand{\coNP}{\mathbf{coNP}}
\newcommand{\EXP}{\mathbf{EXP}}
\newcommand{\BPP}{\mathbf{BPP}}
\newcommand{\RP}{\mathbf{RP}}
\newcommand{\NEXP}{\mathbf{NEXP}}
\newcommand{\PH}{\mathbf{PH}}
\newcommand{\PSPACE}{\mathbf{PSPACE}}
\newcommand{\TIME}{\mathbf{TIME}}
\newcommand{\DTIME}{\mathbf{DTIME}}
\newcommand{\NTIME}{\mathbf{NTIME}}
\newcommand{\LOG}{\mathbf{LOGSPACE}}
\newcommand{\SIZE}{\mathbf{SIZE}}
\newcommand{\AM}{\mathbf{AM}}
\newcommand{\MA}{\mathbf{MA}}

\newcommand{\mf}[1]{\mathbf{#1}}

\def \F {{\mathbb F}}
\def \N {{\mathbb N}}

\def \ATIME{{\mathsf{ATIME}}}
\def \NTIME{{\mathsf{NTIME}}}
\def \eps {{\varepsilon}}

\def \ASPACE{{\mathsf{ASPACE}}}
\def \SPACE{{\mathsf{SPACE}}}
\def \TIME{{\mathsf{TIME}}}
\def \BPL{{\mathbf{BPL}}}

\def \poly{\text{poly}}

\begin{document}
	
	
	\begin{center}
		\Large
		6.541/18.405 Problem Set 3
		
		\vspace{3pt}
		\normalsize
		due on {\bf Thursday, May 2, 11:59pm}
	\end{center}
	
	{\bf Rules:} You may discuss homework problems with other students and you may work in groups, but we require that you {\em try to solve the problems by yourself before discussing them with others}. Think about all the problems on your own and do your best to solve them, before starting a collaboration. If you work in a group, include the names of the other people in the group in your written solution. {\bf Write up your {\em own} solution to every problem}; don't copy answers from another student or any other source. Cite {\bf all} references that you use in a solution (books, papers, people, websites, etc) at the end of each solution. 
	
	We encourage you to use \LaTeX, to compose your solutions. The source of this file is also available on Piazza, to get you started!
	
	{\bf How to submit:} Use Gradescope entry code \textbf{2P3PEN}.\\ \textbf{\large Please use a separate page for each problem.} 

\section*{Problem 1: Circuit Lower Bounds from Pseudorandom Generators (3 Points)}

\subsection*{Question}
We showed that circuit lower bound implied ``good'' PRGs. Here is a sort-of converse:

Show that if there is a $O(\log(n))$-seed 1/10-pseudorandom generator computable in $2^{O(m)}$ time on $m$-bit seeds, then there is an $\eps>0$ such that $\DTIME[2^{O(n)}]\not\subset\SIZE[2^{\eps n}]$.

\subsection*{Answer}
\textbf{TODO: clean this up!  Currently messy enough there is a small chance my approach doesn't work.}

Say there exists such a pseudorandom generator $g : \{0, 1\}* \to \{0, 1\}*$ computed
by Turing machine $G$ running in $2^{km + l}$ time.
WLOG, say that for all $n$, $|x| = c \log(n) \implies |g(x)| = n$.
For any circuit $C$ of size $n$,
$$
|Pr_{x \in \{0, 1\}^{c \log(n)}}[C(g(x)) = 1] - Pr_{x \in \{0, 1\}^n}[C(x) = 1] | < 1/10
$$

The idea is going to be that in time $2^m \times 2^{km} = 2^{(k+1)m}$, a Turing machine can run $g$ on every length $m$ string, and compute $Pr_{x \in \{0, 1\}^{c \log(n)}}[C(g(x)) = 1]$ exactly, but no circuit of size $2^m$ can do this.

% Fix a sufficiently large $n$, and let $x^* \in \{0, 1\}^{c \log(n) + 1}$ such that $$x^* \notin \{g(y) : y \in \{0, 1\}^{c \log(n)}\}$$

Consider the decision problem $f : \{0, 1\}^* \to \{0, 1\}$ where
$$
f(x) = 1 \iff \exists y \in \{0, 1\}^{|x| - 1} \text{ s.t. } g(y) = x \qquad (*)
$$
Suppose for contradiction that $f \in \SIZE[2^n]$.
Let $C$ be the circuit of size $2^n$ that decides this for a given $n$.
Say $m = cn$ (so $m = c\log(2^n)$).
Observe
$$
Pr_{y \in \{0, 1\}^m}[C(g(y)_{1:m+1}) = 1] = 1
$$
Here, $g(y)_{1:m+1}$ is the first $m+1$ bits of $g(y)$.

However, 
$$
Pr_{x \in \{0, 1\}^{2^n}}[C(x_{1:m+1}) = 1] \leq 1/2
$$
because only half of the $m+1$ bit strings can be in the range of a function with domain $\{0, 1\}^m$.
This contradicts $(*)$.
Thus $f \notin \SIZE[2^n]$.
But certainly $f \in \DTIME[2^{O(n)}]$, because it is possible to loop over all $2^n$ $y$ values of length $n$, and for each one check if $x = g(y)$ in time $2^{O(n)}$.  This yields an algorithm for deciding $f$ with total runtime $2^n 2^{O(n)} = 2^{O(n) + n} = 2^{O(n)}$.

% Here, $C$ is the description of a circuit of size $2^m$, and $m$ and $s$ are integers.


\newpage
\section*{Problem 2: Randomized Approximate Counting with an NP Oracle (12 pts, 3 for each sub-problem)}

\subsection*{Question}

We will develop a real-life application of SAT solvers.
{\bf Assume $\mathbf{P}=\mathbf{NP}$ in this question.} Let $H_{n,k}$ be a pairwise independent hash family of functions from $\{0,1\}^n$ to $\{0,1\}^k$.
\begin{itemize}
	\item[(a)] Prove that there is a constant $p \in (0,1)$ and a constant $\eps > 0$ such that for every $k$ and  $S \subseteq \{0,1\}^n$, 
	
	\begin{itemize} 
	\item[$\bullet$] if $|S| \leq 2^{k-2}$, then \[\Pr_{h \in H_{n,k}}[\text{there is an $x \in S$ such that $h(x) = 0^k$}] < p - \eps,\] and
	\item[$\bullet$] if $|S| \geq 2^{k-1}$, then \[\Pr_{h \in H_{n,k}}[\text{there is an $x \in S$ such that $h(x) = 0^k$}] > p + \eps.\] 
\end{itemize}
		\item[(b)]
		Use part (a) to show that that there is a randomized polynomial-time algorithm that approximates \#\textsf{SAT} within a factor of 4. More precisely, there is a randomized polynomial-time algorithm that given any Boolean formula $F$ outputs a number $K$ such that $\#\textsf{SAT}(F)/2 \leq K \leq 2\cdot \left(\#\textsf{SAT}(F)\right)$.
	\item[(c)]
	Show that for any constant $\varepsilon>0$, there is a randomized polynomial-time algorithm that approximates $\#\textsf{SAT}$ within a factor of $1+\varepsilon$. (Hint: Try to modify the given formula $F$ in some natural way that changes the number of SAT assignments, then feed the modification to your algorithm from part (b).)
	\item[(d)]
		Show that you can derandomize the algorithm.	That is, prove that if $\P = \NP$ then for every function $f\in \#\mathbf{P}$, and any constant $\varepsilon>0$, there is a deterministic polynomial-time algorithm that approximates $f$ within a factor of $1+\varepsilon$. (Warning: the approximate counting problem is \emph{not} a decision problem, so you cannot just ``plug in'' $\P = \NP$ here\dots)
\end{itemize}

\newpage
\subsection*{Answer}
\subsubsection*{Answer to (a)}

Fix $S$ s.t. $|S| \leq 2^{k - 2}$.

For $x \in S$, let $A_x$ denote the event $A_x = \{h : h(x) = 0^k\}$.
We wish to show $\Pr[\cup_{x \in S} A_x] < p - \eps$.

By the inclusion-exclusion principle, letting $x_i$ denote the $i$th largest value in $S$,
\begin{multline*}
\Pr[\cup_{x \in S} A_x]
\leq
\sum_{i=1}^{|S|} \Pr[A_{x_i}]
- \sum_{i=1}^{|S|} \sum_{j=1}^{i-1} \Pr[A_{x_i} \cap B_{x_j}]
+ \sum_{i=1}^{|S|} \sum_{j=1}^{i-1} \sum_{k = 1}^{j-1} \Pr[A_{x_i} \cap A_{x_j} \cap A_{x_k}] \\
%
= \frac{1}{2^k}|S| - \frac{1}{2^{2k}}{|S| \choose 2} + \sum_{k = 1}^{j-1} \Pr[A_{x_i} \cap A_{x_j} \cap A_{x_k}] \\
%
\leq \frac{1}{2^k}|S| - \frac{1}{2^{2k}}{|S| \choose 2} + \frac{1}{2^{2k}}{|S| \choose 3} \\
%
\leq \frac{1}{4} - \frac{1}{2^{2k}}{|S| \choose 2} + \frac{1}{2^{2k}}{|S| \choose 3} = \frac{1}{4} - \frac{|S|^2}{2^{2k + 1}} + \frac{|S|}{2^{2k+1}} + \frac{1}{2^{2k}}{|S| \choose 3} \\
%
\leq \frac{1}{4} - \frac{1}{32} + \frac{1}{2^{k + 3}} + \frac{1}{2^{2k}}{|S| \choose 3} \\
%
\leq \frac{1}{4} - \frac{1}{32} + \frac{1}{2^{k + 3}} + \frac{|S|(|S| - 1)(|S| - 2)}{6} \frac{1}{2^{2k}} \\ 
%
\leq \frac{1}{4} - \frac{1}{32} + \frac{1}{2^{k + 3}} +
\frac{|S|^3 - 3|S|^2 + 2|S|}{6} \frac{1}{2^{2k}} \\ 
\leq \frac{1}{4} - \frac{1}{32} + \frac{1}{2^{k + 3}} + 
%
% = |S|/2^k
% - \sum_{i=1}^{|S|}{\frac{i - 1}{2^{2k}}  } + \sum_{i=1}^{|S|} \sum_{j=1}^{i-1} \sum_{k = 1}^{j-1} \Pr[A_{x_i} \cap A_{x_j} \cap A_{x_k}] \\
% = |S|/2^k - \frac{|S|^2 - |S|}{2k^{2k}} + \sum_{i=1}^{|S|} \sum_{j=1}^{i-1} \sum_{k = 1}^{j-1} \frac{1}{2^{2k}}\\
% %
% % \leq 1/4 - (|S|^2 - |S|)/k^{2k}
% = |S|/2^k - (|S|^2 - |S|)/k^{2k} +
% \frac{1}{2^{2k}} \frac{(|S|)(|S| - 1)(|S| - 2)}{3}
%\sum_{i=1}^{|S|} \sum_{j=1}^{i-1} (j (j - 1))/2
\end{multline*}
[TODO]

[TODO TODO]

% Then
% % \begin{multline*}
% % \Pr_{h \in H_{n, k}}[\exists x \in S . h(x) = 0^k] \\
% % \leq
% % \sum_{x \in S} \Pr [h(x) = 0^k]
% % - \sum_{x \neq y \in S} \Pr[h(x) = 0^k \wedge h(y) = 0^k]
% % + \sum_{x \neq y \neq z \in S} \Pr[h(x) = 0^k \wedge h(y) = 0^k \wedge h(z) = 0^k] \\
% % = \sum_{x \in S} \frac{1}{2^k}
% % \leq 2^{k-2}/2^k = 1/4
% % \end{multline*}
% where the inequality follows from the union bound, and is strict
% because $\Pr[h(x) = 0^k \wedge h(y) = 0^y] \neq 0$ for all $x \neq y$.

% First inequality -> union bound -> Pr <= 1/4.
% And since the events overlap, we actually have < 1/4.

% For any x, Pr[x is only value s.t. h(x) = 0^k]
% = Pr[h(x) = 0^k and for all y neq x, h(y) != 0^k]
% = Pr[h(x) = 0^k] - Pr[h(x) = 0^k AND exists y . h(y) = 0^k]
% >= Pr[h(x) = 0^k] - sum_y[P(h(x) = 0^k AND h(y) = 0^k)]
% = Pr[h(x) = 0^k] - (|S| - 1)p^2
%   where p = Pr[h(x) = 0^k] = 1/2^k
% = 1/2^k - (|S| - 1)(1/2^{2k})
% > 1/2^k - |S|/2^{2k}
% >= 1/2^k - 2^{k-1}2^{-2k} = 1/2^k - 1/2^{k + 1} = 1/2^{k + 1} = p/2

% So P[exists a unique S in x with h(x) = 0^k]
% = sum_{x \in S} Pr[x is only value s.t. h(x) = 0^k]
%    [equality since disjoint events]
% > sum_{x \in S} 1/2^{k + 1} = 1/2^{k-1} 1/2^{k + 1} = 1/4.

% So we certainly have P1_k < 1/4 and P2_k > 1/4, for any k and S.
% But how can we show we can get P1_k < 1/4 - eps, P2_k > 1/4 + eps
% for a fixed eps independent of k?

% I think the idea is that for P1, we can say the < gap is at least
% Pr[there exist a distinct x and y s.t. h(x)=h(y)=0^k]
% and we can show that this probability is very close to 1/4 * 1/4.
%
% For P2, -- TODO.

\newpage
\subsection*{Answer to (b)}
Let $S = \{x : F(x) = 1\}$.
Say $|S| \in [2^{k-2}, 2^{k-1}]$.
% By part (a), $\Pr_h[\exists x \in S . h(x) = 0^k] 

Algorithm:
For each $k = 0, \dots, |x|$,
	Do N times:
		Check if F and [h(x) = 0] is satisfiable.

	If $|S| \leq 2^{k-2}$, with high probability, it will be satisfied $< N(p - \epsilon)$ times.
	If $|S| \geq 2^{k-1}$, with high probability, it will be satisfied $> N(p - \epsilon)$ times.

So for very large N, there will be some $K$ where for $k < K$, $< N(p + \frac{\eps}{2})$ are satisfied and for $k > K$, $> N(p + \frac{\eps}{2})$ are satisfied.

So our algorithm can be to return $2^{R - 1}$ (or is it $2^{R - \frac{1}{2}}$) where $R$ is the first value of $k$ where the count was $> N(p + \frac{\eps}{2})$.  We just have to show that this succeeds with high probability.

[TODO: fill in the details]

\newpage
\subsection*{Answer to (c)}

Let $F$ be a formula on variables $x_1, \dots, x_n$.
Let $F_2$ be a formula, identical to $F$, but on a distinct set of variables $y_1, \dots, y_n$.
And in factor for each $i \in \mathbb{N}$, let $F_i$ be a formula identical to $F$, but on a unique set of variables.

Let $G_i = G_1 \wedge G_2 \wedge \dots \wedge G_i$, a formula on $ni$ variables.
Observe that if $F$ has $s$ satisfying assignments, $G_i$ has $s^i$ satisfying assignments.

Choose $i$ large enough that $(1 + \epsilon)^i > 4$.
Let $s_i$ denote the number of satisfying assignments to $G_i$.
Run our algorithm from part (b) on $G_i$ to find a value $K$ such that
$K \in [s_i/2, 2s_i]$.
Then $s_i \in [K/2, 2K]$.
Thus $s^i \in [K/2, 2K]$.
Let $k = K/2$, so $s^i \in [k, 4k]$.
Then $$s \in [(k)^{1/i}, 4^{(1/i)}(k^{1/i})] \subseteq [(k)^{1/i}, (1 + \epsilon)(k^{1/i})]$$

% We want to go from factor $2$ to factor $1 + \eps$.
% Say $F$ has $s$ satisfying assignments out of $2^n$.
% Say I add in a new clause to $F$ and produce a formula $G$ with
% $\frac{1}{2}s + \frac{1}{2}$ satisfying assignments.
% Say I find that $\frac{1}{2}s + \frac{1}{2} \in [K/2, 2K]$.
% Then
% $s + 1 \in [K, 4K]$ so $s \in [K - 1, 4K - 1]$.
% This doesn't help.

% Say instead $G$ has
% $2s$ satisfying assignments.
% Say I find that $2s \in [K/2, 2K]$.
% Then
% $s \in [K/4, K]$.
% If I take $k = K/8 + K/2 = \frac{5K}{8}$, then I have
% $s \in [\frac{2}{5}k, \frac{8}{5}k]$.
% But this still a window of width 4x, which doesn't help.

% Say $G$ has $ms$ satisfying assignments, and $ms \in [K/2, 2K]$.
% Then $s \in [K/(2m), 2K/m]$. If I take $k = \frac{K}{4m} + \frac{4K}{4m} = \frac{5K}{4m}$ then I get
% $s \in [\frac{2}{5}k]

\newpage
\subsection*{Answer to (d)}
Part (c) showed that if $\P = \NP$, then
$\#\P \in \BPP$.

Let $A(F, r)$ be a randomized algorithm with randomness $r$ that, with probability $1 - \delta$, outputs a $1 + \eps/2$ approximation to $\#\textsf{SAT}(F)$.

Here is a deterministic algorithm to check if $\#\textsf{SAT}(F) \leq \rho(1 + \eps)$ for any $\rho$.
Using the fact that 

\newpage
\section*{Problem 3: Constant Round Arthur-Merlin Collapses (3 points)}

\subsection*{Question}
Prove that for every fixed positive integer $k$, $\AM[k]\subseteq \AM[2]$.

\medskip

\emph{Hint: Try error-reduction, to make the probability of error very small.}


\subsection*{Answer}

WLOG assume $k$ is even. Consider an AM[k] protocol to decide $f(x)$.  Say on any iteration, a sequence of messages $r_1, m_1, r_2, m_2, \dots, r_{k/2}, m_{k/2}$ are sent, where $r_i$ are the random messages from the verifier, and $m_i$ are the messages from the prover.
% Let $M$ be an upper bound (possibly dependent on the size of the input $x$ to the Arthur Merlin protocol) on the total size of the prover's mesasges,
% $M \geq \sum_{j} |m_{j}|$.
Fix a given prover $P$.  Let $A_\text{acc}$ denote the event that the $r_i$ result in $V$ accepting, and let $A_\text{rej}$ denote the event that the $r_i$ result in $V$ rejecting.
By the definition of an AM protocol, if $f(x) = 1$ there is a prover so $\Pr[A_\text{acc}] > 2/3$ and if $f(x) = 0$ then for every prover, $\Pr[A_\text{rej} < 1/3]$.

By the error reduction lemma, by running this protocol in parallel $O(k)$ times (with a minor modification to be described in a moment), we obtain an AM[k] protocol such that if $f(x) = 1$, there is a prover so $\Pr[A_\text{acc}] > 1 - 2^{-k}$, and if $f(x) = 0$, for every prover, $\Pr[A_\text{rej}] < 2^{-k}$.

% The following is the modification to simply running the original protocol in parallel that is needed for this to work (or, at least, I have not seen how error reduction could work without this).  We also now need the verifier to check that it is possible that the messages the prover is sending are possible from a single parallel running many times in parallel (so that the new ``parallel track prover'' isn't cheating by respoding to each )
% same prover is being run in parallel.  That is, if two parallel tracks send the same initial sequence of random bits, the prover's messages up to that point must be identical in both branches, for the verifier to accept.)
\textbf{[TODO: do we need to prove this lemma?]}

Now, consider the following $\AM[2]$ protocol.  On the first round,
the verifier sends a sequence of random bits $r_1, r_2, \dots, r_{k/2}$,
where each sequence of bits is as long as the longest sequence that $r_i$ could have been in the $\AM[k]$ protocol with exponential error bounds.
The prover will send a message which is a concatenation $m_1, m_2, \dots, m_{k/2}$, and the verifier will accept if $r_1, m_1, r_2, m_2, \dots, m_{k/2}$ would have been an acceptable transcript in the $\AM[k]$ protocol with exponential error bounds.

\medskip
\noindent \textbf{Analysis.} If $f(x) = 1$, then there is a prover which would have almost certainly been accepted in the $\AM[k]$ version of the protocol, and running it in this $\AM[2]$ will succeed with equally high probability.
Now say $f(x) = 0$.  Let $r$ denote the full string of randomness sent by the verifier and let $m$ denote the prover's full response.
It is sufficient to upper-bound $\Pr_r[\exists m . V(x, m, r) = 1]$.
By the union bound,
$$
\Pr_r[\exists m . V(x, m, r) = 1] \leq \sum_{m}{\Pr_r[V(x, m, r) = 1]} \leq \sum_m{2^{-k}} \leq 2^M/2^k
$$
where $M$ is an upper bound on the length of $m$, and $k$ is the value we chose in the error bound for the reduced-error $\AM[k]$ protocol.
If we choose to set $k > M + 2$, we get 
$$
\Pr_r[\exists m . V(x, m, r) = 1] < 1/4
$$
which is certainly sufficient.


\newpage

\section*{Problem 4: AM Protocol for Set Lower Bound (6 Points, 2 for each sub-problem)}

\subsection*{Question}

In this problem, we will develop an $\AM$ protocol for proving a set lower bound, which is used as a subroutine in the $\AM$ protocol for graph non-isomorphism. In a set lower bound protocol, the prover needs to prove to the verifier that given a (large) set $S\subseteq \{0,1\}^m$ (where membership in $S$ is efficiently verifiable), $S$ has cardinality at least $K$, up to a factor of $2$. More precisely, given any $K$,
\begin{itemize}
\item  if $|S| \ge K$ then the prover can make the verifier accept with high probability; 
\item if $|S| < K/2$ then the verifier rejects with high probability regardless of what the prover does.
\end{itemize}


\begin{enumerate}
    \item[(a)] Let $H_{m,k}$ be a pairwise independent hash family of functions from $\{0,1\}^m$ to $\{0,1\}^k$. Use the pairwise independent hash family $H_{m,k}$ to give a $2$-round $\AM$ protocol for the set lower bound problem described above.
    
    \item[(b)] Show that there exists an $\AM$ protocol for set lower bound with perfect completeness.

    \emph{Hint: Consider the case where the prover uses multiple hash functions $h_1,\dots, h_n$ so that $\bigcup_{i = 1}^n h_i(S) = \{0,1\}^k$.}
    
    \item[(c)] Generalize the idea from part (b) to show that every problem in $\MA$ has a protocol with perfect completeness. Namely, show that for every language $L\in \MA$, there exists a probabilistic polynomial time verifier $V$ such that 
    \begin{enumerate}
        \item[-] If $x\in L$, then there exists $m$ such that $\Pr_r[V(x,r,m) = 1] = 1$.
        \item[-] If $x\not\in L$, then for all $m$, $\Pr_r[V(x,r,m)]\le 1/3$.
    \end{enumerate}
\end{enumerate}

\newpage
\subsection*{Answer to (a)}

% The verifier will send $l$ uniformly random $m$ bit strings $y_1, \dots, y_l$.
\textbf{The protocol.} The verifier will send $l$ random pairwise independent hash functions $h_1, \dots, h_l$.  (Each one can be sent in $O(mk)$ bits.)

The prover will send back $K$, and then, for each $y_i$, either a message saying there is no $x \in S$ s.t. $h_i(x) = 0^k$, or a string $x_i$.
The verifier will reject if any $x_i$ does not satisfy $h_i(x_i) = 0^k$ or if any $x_i \notin S$.
If the prover sends back $\geq \frac{3}{4}\frac{K}{2^k}l$ valid $x_i$, the verifier will accept.  The verifier will reject otherwise.

\medskip
\noindent \textbf{Analysis.}
Say $|S| \geq K$.
Then for any $h_i$,
\begin{multline*}
	\Pr[\exists x \in S . h_i(x) = 0^k]
	\geq \sum_{x \in S}\frac{1}{2^k} - \sum_{x \neq y \in S}\frac{1}{2^{2k}} \\
	> \frac{K}{2^k} - \frac{K^2}{2^{2k + 1}}
	= \frac{K}{2^k} - \frac{1}{2} (\frac{K}{2^k})^2
\end{multline*}




\newpage
\section*{Problem 5: The Limits of PCPs (4 Points, 2 for each sub-problem)}
\subsection*{Question}
Recall that in class we defined $\mf{PCP}_s[r(n),q(n)]$ to be the set of functions with probabilistically checkable proofs having ``soundness'' $s$. In general, we can parametrize the ``completeness'' as well. 

Specifically, define $f:\{0,1\}^* \rightarrow \{0,1\}$ to be in $\mf{PCP}_{c,s}[r(n),q(n)]$ if there is a probabilistic polynomial time algorithm $V$ such that for all $x$, $V$ uses $O(r(|x|))$ random bits, asks $q(|x|)$ oracle queries to a proof string $P$ non-adaptively, must decide whether accept or reject, and
\begin{itemize}
	\item
	$f(x) = 1 \Longrightarrow$ there is a $P$ such that $\Pr[V^P(x) \textrm{ accepts}] \geq c$.
	\item
	$f(x) = 0 \Longrightarrow$ for all $P$, $\Pr[V^P(x) \textrm{ accepts}] < s$.
\end{itemize}

Note that in this generalized version, when $f(x) = 1$, we do not require the verifier to accept with probability $1$ on some proof $P$. 

In the PCP lectures, it was proved that $\mf{PCP}_{1,1}(\log n, 3)=\mathbf{NP}$. The number $3$ here is actually the smallest possible. In this problem, you are asked to show that if we reduce the number of queries to two or one, the classes become $\mathbf{P}$. Prove that:
\begin{enumerate}[(a)]
	\item
	for every $0<s\leq  c\leq 1$, $\mf{PCP}_{c,s}(\log n,1)=\mathbf{P}$.
	\item
	for every $0<s\leq 1$, $\mf{PCP}_{1,s}(\log n,2)=\mathbf{P}$.
\end{enumerate} 
\emph{Hint: Think about these 1-query and 2-query PCPs from the CSP/inapproximability perspective: what you want to show is that the resulting CSPs are in fact easy to solve.}

\smallskip

{\bf Extra credit:} Prove that for every $0<s\leq 1$, $\bigcup_{k \geq 1} \mf{PCP}_{1,s}(n^k,2) \subseteq \mf{PSPACE}$

\smallskip

\emph{Hint: Use the fact that 2SAT is in NL.} 

\newpage
\subsection*{Answer to (a)}
For contradiction, say $\mathbf{PCP}_{c, s}(\log n, 1) \not\subseteq \P$.
Let $f \in \mathbf{PCP}_{c, s}(\log n, 1) \setminus \P$ be a decision problem,
decided by verifier $V$.
I will contradict this by constructing a polynomial time Turing machine that decides $f$.
It will operate as follows.  Say input $x$ is given.
For each $r \in \{0, 1\}^{\log n}$, let $y_r = 1$ if $V(x, r, 1) = 1$ and let $y_r = 0$ otherwise. (Each of these can be computed in polytime.) Here I write $V(x, r, y)$ to denote the value returned by verifier $V$ on input $x$ and randomness $r$, given that it received value $y$ after the one query it makes to the prover (which is a deterministic function of $x$ and $r$).

Observe that if $f(x) = 1$, then $V(x, r, y_r) = 1$ for at least $c$ of the possible $r$ values.
If $f(x) = 0$, then $V(x, r, y_r) = 0$ for at least $1 - s$ of the possible $r$ values (and in fact this would be true for any assignment to the $y$ values).
Since there are only $n$ distinct $y_r$ values, our algorithm can simply compute $V(x, r, y_r)$ for each $r \in \{0, 1\}^n$, and accept if $\geq cn$ of them are true.

\subsection*{Answer to (b)}
In this problem I will write $V(x, r, y, z)$ to be the value that $V$ outputs on input $x$ and randomness $r$, given that it receives response $y$ and $z$ from the prover on the two queries it makes.  Since the queries are non-adaptive, for any verifier, $y$ and $z$ are a function of $x$ and $r$.

Again for contradiction, say $\mathbf{PCP}_{1, s}(\log n, 1) \not\subseteq \P$.
Let $f \in \mathbf{PCP}_{1, s}(\log n, 1) \setminus \P$.
I will describe a polytime algorithm that decides $f$.

Fix input string $x$.
We will construct a 2SAT instance on variables $Y_0, \dots, Y_{n-1}, Z_0, \dots, Z_{n-1}$.
For each $r \in \{0, 1\}^{\log n} = \{0, 1, \dots, n-1\}$, we will construct a clause
$C_r$ as follows.
Run $V(x, r, y, z)$ on this $x$ and $r$ for each of the 4 permutations of possible
values for $y, z$.
Let $C_r$ be a 2SAT formula on variables $Y_r, Z_r$ so that $C_r(y, z) = V(x, r, y, z)$ for all $y$, $z$.\footnote{
Here are the details of the construction of $C_r$.
If $V(x, r, y, z)$ is never 1, set $C_r = Y_r \wedge \neg Y_r$.
If $V(x, r, y, z) = 1$ only on $y^*, z^*$, set $C_r = (Y_r = y^*) \wedge (Z_r = z^*)$.
If $V(x, r, y, z) = 1$ exactly when $y = 1$, set $C_r = Y_r$; do the analogus thing if it is 1 exactly when $y = 0$ or exactly when $z = 1$ or exatly when $z = 0$.
If $V(x, r, y, z) = 1$ exactly when $y = z$ make $C_r = (Y_r \vee \neg Z_r) \wedge (\neg Y_r \vee Z_r)$.
If $V(x, r, y, z) = 1$ exactly when $y \neq z$ make $C_r = (Y_r \vee Z_r) \wedge (\neg Y_r \vee \neg Z_r)$.
If $V(x, r, y, z) = 1$ in every case except $(y^*, z^*)$, set $C_r = (Y_r \neq y^*) \vee (Z_r \neq z^*)4.
If $V(x, r, y, z) = 1$ on all $y, z$, set $C_r = \eps$, the empty clause.
% 	If $V(x, r, y, z) = 1$ for 3 assignments to $y$ and $z$, let $C_r = (\neg) Y_r \vee (\neg) Z_r$ where we optionally include negations $\neg$, to make $C_r$ the clause which accepts exactly the 3 permutations of $(y, z)$ that $V$ accepted.
% 	If $V(x, r, y, z) = 1$ for 2 assignments)
}

If $f(x) = 1$, then for every $r$, there is an assignment to $Y_r, Z_r$ so that $C_r$ is satisfied (this is because $c = 1$).
If $f(x) = 0$, then for every assignment to $Y_r, Z_r$,
$< sn$ of the $C_r$ are satisfied.
Let $C = \wedge_{r} C_r$, which is a conjunction of 2CNF formulae, and is thus a 2CNF formula itself.
We can determine whether $C$ is satisfiable in polynomial time (this is just a 2SAT problem); if it is, then we must have $f(x) = 1$, and if not, we must have $f(x) = 0$.


\end{document}